{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Testing for Data Science in Python\n",
    "\n",
    "#### Course Description\n",
    "Every data science project needs unit testing. It comes with huge benefits - saving a lot of development and maintenance time, improving documentation, increasing end-user trust and reducing downtime of productive systems. As a result, unit testing has become a must-have skill in the industry, used by almost every company. This course teaches unit testing in Python using the most popular testing framework pytest. By the end of this course, you will have written a complete test suite for a data science project. In the process, you will learn to write unit tests for data preprocessors, models and visualizations, interpret test results and fix any buggy code. You will also learn advanced concepts like TDD, test organization, fixtures and mocking so that you can test your own data science projects properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Unit testing basics\n",
    "\n",
    "In this chapter, you will get introduced to the pytest package and use it to write simple unit tests. You'll run the tests, interpret the test result reports and fix bugs. Throughout the chapter, we will use examples exclusively from the data preprocessing module of a linear regression project, making sure you learn unit testing in the context of data science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your first unit test using pytest\n",
    "The data file containing housing area and prices uses commas as thousands separators, e.g. \"2,081\" or \"314,942\", as you can see in the IPython Shell.\n",
    "\n",
    "The convert_to_int() function takes a comma separated integer string as argument, and returns the integer. Therefore, the expected return value of convert_to_int(\"2,081\") is the integer 2081.\n",
    "\n",
    "This function is defined in the module preprocessing_helpers.py. But it is not known if the function is working properly.\n",
    "\n",
    "#### Instructions \n",
    "- Import the pytest package.\n",
    "- Import the function convert_to_int().\n",
    "- Complete the name of the unit test by adding the prefix which pytest uses to distinguish unit tests from ordinary functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function convert_to_int()\n",
    "from preprocessing_helpers import convert_to_int\n",
    "\n",
    "# Complete the unit test name by adding a prefix\n",
    "def test_on_string_with_one_comma():\n",
    "  # Complete the assert statement\n",
    "  assert convert_to_int(\"2,081\") == 2081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.7.6, pytest-5.4.1, py-1.8.1, pluggy-0.13.1\n",
      "rootdir: C:\\Users\\juanc\\OneDrive - Universidad de los andes\\Datacamp\\Python_Programmer_Track\\13 - Unit Testing for Data Science in Python\\Code\n",
      "plugins: hypothesis-5.5.4, arraydiff-0.3, astropy-header-0.1.2, doctestplus-0.5.0, openfiles-0.4.0, remotedata-0.3.2\n",
      "collected 1 item\n",
      "\n",
      "test_convert_to_int.py F                                                 [100%]\n",
      "\n",
      "================================== FAILURES ===================================\n",
      "________________________ test_on_string_with_one_comma ________________________\n",
      "\n",
      "    def test_on_string_with_one_comma():\n",
      "        test_argument = \"2,081\"\n",
      "        expected = 2081\n",
      "        actual = convert_to_int(test_argument)\n",
      "        # Format the string with the actual return value\n",
      "        message = \"convert_to_int('2,081') should return the int 2081, but it actually returned {0}\".format(actual)\n",
      "        # Write the assert statement which prints message on failure\n",
      ">       assert expected == actual, message\n",
      "E       AssertionError: convert_to_int('2,081') should return the int 2081, but it actually returned 2081\n",
      "E       assert 2081 == '2081'\n",
      "\n",
      "test_convert_to_int.py:11: AssertionError\n",
      "=========================== short test summary info ===========================\n",
      "FAILED test_convert_to_int.py::test_on_string_with_one_comma - AssertionError...\n",
      "============================== 1 failed in 0.08s ==============================\n"
     ]
    }
   ],
   "source": [
    "!pytest test_convert_to_int.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pytest\n",
      "from preprocessing_helpers import convert_to_int\n",
      "\n",
      "def test_on_string_with_one_comma():\n",
      "    test_argument = \"2,081\"\n",
      "    expected = 2081\n",
      "    actual = convert_to_int(test_argument)\n",
      "    # Format the string with the actual return value\n",
      "    message = \"convert_to_int('2,081') should return the int 2081, but it actually returned {0}\".format(actual)\n",
      "    # Write the assert statement which prints message on failure\n",
      "    assert expected == actual, message\n"
     ]
    }
   ],
   "source": [
    "!cat test_convert_to_int.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Intermediate unit testing\n",
    "\n",
    "In this chapter, you will write more advanced unit tests. Starting from testing complicated data types like NumPy arrays to testing exception handling, you'll do it all. Once you have mastered the science of testing, we will also focus on the arts. For example, we will learn how to find the balance between writing too many tests and too few tests. In the last lesson, you will get introduced to a radically new programming methodology called Test Driven Development (TDD) and put it to practice. This might actually change the way you code forever!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write an informative test failure message\n",
    "The test result reports become a lot easier to read when you make good use of the optional message argument of the assert statement.\n",
    "\n",
    "In a previous exercise, you wrote a test for the convert_to_int() function. The function takes an integer valued string with commas as thousand separators e.g. \"2,081\" as argument and should return the integer 2081.\n",
    "\n",
    "In this exercise, you will rewrite the test called test_on_string_with_one_comma() so that it prints an informative message if the test fails.\n",
    "\n",
    "#### Instructions \n",
    "- Format the message string so that it shows the actual return value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from preprocessing_helpers import convert_to_int\n",
    "\n",
    "def test_on_string_with_one_comma():\n",
    "    test_argument = \"2,081\"\n",
    "    expected = 2081\n",
    "    actual = convert_to_int(test_argument)\n",
    "    # Format the string with the actual return value\n",
    "    message = \"convert_to_int('2,081') should return the int 2081, but it actually returned {0}\".format(actual)\n",
    "    # Write the assert statement which prints message on failure\n",
    "    assert expected == actual, message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.7.6, pytest-5.4.1, py-1.8.1, pluggy-0.13.1\n",
      "rootdir: C:\\Users\\juanc\\OneDrive - Universidad de los andes\\Datacamp\\Python_Programmer_Track\\13 - Unit Testing for Data Science in Python\\Code\n",
      "plugins: hypothesis-5.5.4, arraydiff-0.3, astropy-header-0.1.2, doctestplus-0.5.0, openfiles-0.4.0, remotedata-0.3.2\n",
      "collected 1 item\n",
      "\n",
      "test_convert_to_int.py F                                                 [100%]\n",
      "\n",
      "================================== FAILURES ===================================\n",
      "________________________ test_on_string_with_one_comma ________________________\n",
      "\n",
      "    def test_on_string_with_one_comma():\n",
      "        test_argument = \"2,081\"\n",
      "        expected = 2081\n",
      "        actual = convert_to_int(test_argument)\n",
      "        # Format the string with the actual return value\n",
      "        message = \"convert_to_int('2,081') should return the int 2081, but it actually returned {0}\".format(actual)\n",
      "        # Write the assert statement which prints message on failure\n",
      ">       assert expected == actual, message\n",
      "E       AssertionError: convert_to_int('2,081') should return the int 2081, but it actually returned 2081\n",
      "E       assert 2081 == '2081'\n",
      "\n",
      "test_convert_to_int.py:11: AssertionError\n",
      "=========================== short test summary info ===========================\n",
      "FAILED test_convert_to_int.py::test_on_string_with_one_comma - AssertionError...\n",
      "============================== 1 failed in 0.07s ==============================\n"
     ]
    }
   ],
   "source": [
    "!pytest test_convert_to_int.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing float return values\n",
    "The get_data_as_numpy_array() function (which was called mystery_function() in one of the previous exercises) takes two arguments: the path to a clean data file and the number of data columns in the file . An example file have been printed out in the IPython console. It contains three rows.\n",
    "\n",
    "The function converts the data into a 3x2 NumPy array with dtype=float64. The expected return value has been stored in a variable called expected. Print it out to see it.\n",
    "\n",
    "The housing areas are in the first column and the housing prices are in the second column. This array will be the features that will be fed to the linear regression model for learning.\n",
    "\n",
    "The return value contains floats. Therefore you have to be especially careful when writing unit tests for this function.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Complete the assert statement to check if get_data_as_numpy_array() returns expected, when called on example_clean_data_file.txt with num_columns set to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pytest\n",
    "from as_numpy import get_data_as_numpy_array\n",
    "\n",
    "def test_on_clean_file():\n",
    "  expected = np.array([[2081.0, 314942.0],\n",
    "                       [1059.0, 186606.0],\n",
    "  \t\t\t\t\t   [1148.0, 206186.0]\n",
    "                       ]\n",
    "                      )\n",
    "  actual = get_data_as_numpy_array(\"data/example_clean_data.txt\", num_columns=2)\n",
    "  message = \"Expected return value: {0}, Actual return value: {1}\".format(expected, actual)\n",
    "  # Complete the assert statement\n",
    "  assert actual == pytest.approx(actual), message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.7.6, pytest-5.4.1, py-1.8.1, pluggy-0.13.1\n",
      "rootdir: C:\\Users\\juanc\\OneDrive - Universidad de los andes\\Datacamp\\Python_Programmer_Track\\13 - Unit Testing for Data Science in Python\\Code\n",
      "plugins: hypothesis-5.5.4, arraydiff-0.3, astropy-header-0.1.2, doctestplus-0.5.0, openfiles-0.4.0, remotedata-0.3.2\n",
      "collected 1 item\n",
      "\n",
      "test_as_numpy.py .                                                       [100%]\n",
      "\n",
      "============================== 1 passed in 0.04s ==============================\n"
     ]
    }
   ],
   "source": [
    "!pytest test_as_numpy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with multiple assert statements\n",
    "You're now going to test the function split_into_training_and_testing_sets() from the models module.\n",
    "\n",
    "It takes a n x 2 NumPy array containing housing area and prices as argument. To see an example argument, print the variable example_argument in the IPython console.\n",
    "\n",
    "The function returns a 2-tuple of NumPy arrays (training_set, testing_set). The training set contains int(0.75 * n) (approx. 75%) randomly selected rows of the argument array. The testing set contains the remaining rows.\n",
    "\n",
    "Print the variable expected_return_value in the IPython console. example_argument had 6 rows. Therefore the training array has int(0.75 * 6) = 4 of its rows and the testing array has the remaining 2 rows.\n",
    "\n",
    "numpy as np, pytest and split_into_training_and_testing_sets have been imported for you.\n",
    "\n",
    "#### Instructions \n",
    "- Calculate the expected number of rows of the training array using the formula int(0.75*n), where n is the number of rows in example_argument, and assign the variable expected_training_array_num_rows to this number.\n",
    "- Calculate the expected number of rows of the testing array using the formula n - int(0.75*n), where n is the number of rows in example_argument, and assign the variable expected_testing_array_num_rows to this number.\n",
    "- Write an assert statement that checks if training array has expected_training_array_num_rows rows.\n",
    "- Write an assert statement that checks if testing array has expected_testing_array_num_rows rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_six_rows():\n",
    "    example_argument = np.array([[2081.0, 314942.0], [1059.0, 186606.0],\n",
    "                                 [1148.0, 206186.0], [1506.0, 248419.0],\n",
    "                                 [1210.0, 214114.0], [1697.0, 277794.0]]\n",
    "                                )\n",
    "    # Fill in with training array's expected number of rows\n",
    "    expected_training_array_num_rows = 4\n",
    "    # Fill in with testing array's expected number of rows\n",
    "    expected_testing_array_num_rows = 2\n",
    "    actual = split_into_training_and_testing_sets(example_argument)\n",
    "    # Write the assert statement checking training array's number of rows\n",
    "    assert actual[0].shape[0] == expected_training_array_num_rows, \"The actual number of rows in the training array is not {}\".format(expected_training_array_num_rows)\n",
    "    # Write the assert statement checking testing array's number of rows\n",
    "    assert actual[1].shape[1] == expected_testing_array_num_rows, \"The actual number of rows in the testing array is not {}\".format(expected_testing_array_num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.7.6, pytest-5.4.1, py-1.8.1, pluggy-0.13.1\n",
      "rootdir: C:\\Users\\juanc\\OneDrive - Universidad de los andes\\Datacamp\\Python_Programmer_Track\\13 - Unit Testing for Data Science in Python\\Code\n",
      "plugins: hypothesis-5.5.4, arraydiff-0.3, astropy-header-0.1.2, doctestplus-0.5.0, openfiles-0.4.0, remotedata-0.3.2\n",
      "collected 1 item\n",
      "\n",
      "test_train.py .                                                          [100%]\n",
      "\n",
      "============================== 1 passed in 0.07s ==============================\n"
     ]
    }
   ],
   "source": [
    "!pytest test_train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice the context manager\n",
    "In pytest, you can test whether a function raises an exception by using a context manager. Let's practice your understanding of this important context manager, the with statement and the as clause.\n",
    "\n",
    "At any step, feel free to run the code by pressing the \"Run Code\" button and check if the output matches your expectations.\n",
    "\n",
    "#### Instructions \n",
    "\n",
    "- Complete the with statement by filling in with a context manager that will silence the ValueError raised in the context.\n",
    "- Complete the with statement with a context manager that raises Failed if no OSError is raised in the context.\n",
    "- Extend the with statement so that any raised ValueError is stored in the variable exc_info.\n",
    "- Write an assert statement to check if the raised ValueError contains the message \"Silence me!\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in with a context manager that will silence the ValueError\n",
    "with pytest.raises(ValueError):\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytest raised an exception because no OSError was raised in the context.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Fill in with a context manager that raises Failed if no OSError is raised\n",
    "    with pytest.raises(OSError):\n",
    "        raise ValueError\n",
    "except:\n",
    "    print(\"pytest raised an exception because no OSError was raised in the context.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the raised ValueError in the variable exc_info\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    raise ValueError(\"Silence me!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pytest.raises(ValueError) as exc_info:\n",
    "    raise ValueError(\"Silence me!\")\n",
    "# Check if the raised ValueError contains the correct message\n",
    "assert exc_info.match(\"Silence me!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit test a ValueError\n",
    "Sometimes, you want a function to raise an exception when called on bad arguments. This prevents the function from returning nonsense results or hard-to-interpret exceptions. This is an important behavior which should be unit tested.\n",
    "\n",
    "Remember the function split_into_training_and_testing_sets()? It takes a NumPy array containing housing area and prices as argument. The function randomly splits the array row wise into training and testing arrays in the ratio 3:1, and returns the resulting arrays in a tuple.\n",
    "\n",
    "If the argument array has only 1 row, the testing array will be empty. To avoid this situation, you want the function to not return anything, but raise a ValueError with the message \"Argument data_array must have at least 2 rows, it actually has just 1\".\n",
    "\n",
    "#### Instructions \n",
    "\n",
    "- Fill in with the correct context manager that checks if split_into_training_and_testing_sets() raises a ValueError when called on test_argument, which is a NumPy array with a single row.\n",
    "- Complete the with statement so that information about any raised ValueError will be stored in the variable exc_info.\n",
    "- Write an assert statement to check if the raised ValueError contains the correct message stored in the variable expected_error_msg.\n",
    "- The test test_on_one_row() was written to the test module test_split_into_training_and_testing_sets.py. Run the test in the IPython console and read the test result report. Does the test pass or fail?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import split_into_training_and_testing_sets\n",
    "\n",
    "def test_on_one_row():\n",
    "    test_argument = np.array([[1382.0, 390167.0]])\n",
    "    # Store information about raised ValueError in exc_info\n",
    "    with pytest.raises(ValueError) as exc_info:\n",
    "      split_into_training_and_testing_sets(test_argument)\n",
    "    expected_error_msg = \"Argument data_array must have at least 2 rows, it actually has just 1\"\n",
    "    # Check if the raised ValueError contains the correct message\n",
    "    assert exc_info.match(expected_error_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.7.6, pytest-5.4.1, py-1.8.1, pluggy-0.13.1\n",
      "rootdir: C:\\Users\\juanc\\OneDrive - Universidad de los andes\\Datacamp\\Python_Programmer_Track\\13 - Unit Testing for Data Science in Python\\Code\n",
      "plugins: hypothesis-5.5.4, arraydiff-0.3, astropy-header-0.1.2, doctestplus-0.5.0, openfiles-0.4.0, remotedata-0.3.2\n",
      "collected 1 item\n",
      "\n",
      "test_split_into_training_and_testing_sets.py .                           [100%]\n",
      "\n",
      "============================== 1 passed in 0.05s ==============================\n"
     ]
    }
   ],
   "source": [
    "!pytest test_split_into_training_and_testing_sets.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing well: Boundary values\n",
    "Remember row_to_list()? It takes a row containing housing area and prices e.g. \"2,041\\t123,781\\n\" and returns the data as a list e.g. [\"2,041\", \"123,781\"].\n",
    "\n",
    "A row can be mapped to a 2-tuple (m, n), where m is the number of tab separators. n is 1 if the row has any missing values, and 0 otherwise.\n",
    "\n",
    "For example,\n",
    "\n",
    "- \"123\\t456\\n\" → (1, 0).\n",
    "- \"\\t456\\n\" → (1, 1).\n",
    "- \"\\t456\\t\\n\" → (2, 1).\n",
    "\n",
    "The function only returns a list for arguments mapping to (1, 0). All other tuples correspond to invalid rows, with either more than one tab or missing values. The function returns None in all these cases. See the plot.\n",
    "\n",
    "This mapping shows that the function has normal behavior at (1, 0), and special behavior everywhere else.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Assign actual to the return value of row_to_list() on the argument \"123\\n\", which is an instance of the boundary value (0, 0).\n",
    "- Complete the assert statement to check if row_to_list() indeed returns None for the instance \"123\\t4,567\\t89\\n\" of the boundary value (2, 0).\n",
    "- In the test test_on_one_tab_with_missing_value(), format the failure message with the actual return value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_helpers import row_to_list\n",
    "\n",
    "def test_on_no_tab_no_missing_value():    # (0, 0) boundary value\n",
    "    # Assign actual to the return value for the argument \"123\\n\"\n",
    "    actual = row_to_list(\"123\\n\")\n",
    "    assert actual is None, \"Expected: None, Actual: {0}\".format(actual)\n",
    "    \n",
    "def test_on_two_tabs_no_missing_value():    # (2, 0) boundary value\n",
    "    actual = row_to_list(\"123\\t4,567\\t89\\n\")\n",
    "    # Complete the assert statement\n",
    "    assert actual is None, \"Expected: None, Actual: {0}\".format(actual)\n",
    "    \n",
    "def test_on_one_tab_with_missing_value():    # (1, 1) boundary value\n",
    "    actual = row_to_list(\"\\t4,567\\n\")\n",
    "    # Format the failure message\n",
    "    assert actual is None, \"Expected: None, Actual: {0}\".format(actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing well: Values triggering special logic\n",
    "Look at the plot. The boundary values of row_to_list() are now marked in orange. The normal argument is marked in green and the values triggering special behavior are marked in blue.\n",
    "\n",
    "In the last exercise, you wrote tests for boundary values. In this exercise, you are going to write tests for values triggering special behavior, in particular, (0, 1) and (2, 1).\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Assign the variable actual to the actual return value for \"\\n\".\n",
    "- Complete the assert statement for test_on_no_tab_with_missing_value(), making sure to format the failure message appropriately.\n",
    "- Assign the variable actual to the actual return value for \"123\\t\\t89\\n\".\n",
    "- Complete the assert statement for test_on_two_tabs_with_missing_value(), making sure to format the failure message appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from preprocessing_helpers import row_to_list\n",
    "\n",
    "def test_on_no_tab_with_missing_value():    # (0, 1) case\n",
    "    # Assign to the actual return value for the argument \"\\n\"\n",
    "    actual = row_to_list(\"\\n\")\n",
    "    # Write the assert statement with a failure message\n",
    "    assert actual is None, \"Expected: None, Actual: {0}\".format(actual)\n",
    "    \n",
    "def test_on_two_tabs_with_missing_value():    # (0, 1) case\n",
    "    # Assign to the actual return value for the argument \"123\\t\\t89\\n\"\n",
    "    actual = row_to_list(\"123\\t\\t89\\n\")\n",
    "    # Write the assert statement with a failure message\n",
    "    assert actual is None, \"Expected: None, Actual: {0}\".format(actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing well: Normal arguments\n",
    "This time, you will test row_to_list() with normal arguments i.e. arguments mapping to the tuple (1, 0). The plot is provided to you for reference.\n",
    "\n",
    "Remembering that the best practice is to test for two to three normal arguments, you will write two tests in this exercise.\n",
    "\n",
    "#### Instructions\n",
    "- Assign the variable expected to the expected return value for the normal argument \"123\\t4,567\\n\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_normal_argument_1():\n",
    "    actual = row_to_list(\"123\\t4,567\\n\")\n",
    "    # Fill in with the expected return value for the argument \"123\\t4,567\\n\"\n",
    "    expected = [\"123\", \"4,567\"]\n",
    "    assert actual == expected, \"Expected: {0}, Actual: {1}\".format(expected, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.7.6, pytest-5.4.1, py-1.8.1, pluggy-0.13.1\n",
      "rootdir: C:\\Users\\juanc\\OneDrive - Universidad de los andes\\Datacamp\\Python_Programmer_Track\\13 - Unit Testing for Data Science in Python\\Code\n",
      "plugins: hypothesis-5.5.4, arraydiff-0.3, astropy-header-0.1.2, doctestplus-0.5.0, openfiles-0.4.0, remotedata-0.3.2\n",
      "collected 8 items\n",
      "\n",
      "test_convert_to_int.py F.......                                          [100%]\n",
      "\n",
      "================================== FAILURES ===================================\n",
      "________________________ test_on_string_with_one_comma ________________________\n",
      "\n",
      "    def test_on_string_with_one_comma():\n",
      "        test_argument = \"2,081\"\n",
      "        expected = 2081\n",
      "        actual = convert_to_int(test_argument)\n",
      "        # Format the string with the actual return value\n",
      "        message = \"convert_to_int('2,081') should return the int 2081, but it actually returned {0}\".format(actual)\n",
      "        # Write the assert statement which prints message on failure\n",
      ">       assert expected == actual, message\n",
      "E       AssertionError: convert_to_int('2,081') should return the int 2081, but it actually returned 2081\n",
      "E       assert 2081 == '2081'\n",
      "\n",
      "test_convert_to_int.py:12: AssertionError\n",
      "=========================== short test summary info ===========================\n",
      "FAILED test_convert_to_int.py::test_on_string_with_one_comma - AssertionError...\n",
      "========================= 1 failed, 7 passed in 0.28s =========================\n"
     ]
    }
   ],
   "source": [
    "!pytest test_convert_to_int.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TDD: Tests for normal arguments\n",
    "In this and the following exercises, you will implement the function convert_to_int() using Test Driven Development (TDD). In TDD, you write the tests first and implement the function later.\n",
    "\n",
    "Normal arguments for convert_to_int() are integer strings with comma as thousand separators. Since the best practice is to test a function for two to three normal arguments, here are three examples with no comma, one comma and two commas respectively.\n",
    "\n",
    "```\n",
    "Argument value\tExpected return value\n",
    "\"756\"\t         756\n",
    "\"2,081\"           2081\n",
    "\"1,034,891\"\t   1034891\n",
    "```\n",
    "\n",
    "Since the convert_to_int() function does not exist yet, you won't be able to import it. But you will use it in the tests anyway. That's how TDD works.\n",
    "\n",
    "pytest has already been imported for you.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Complete the assert statement for test_with_no_comma() by inserting the correct boolean expression.\n",
    "- Complete the assert statement for test_with_one_comma() by inserting the correct boolean expression.\n",
    "- Complete the assert statement for test_with_two_commas() by inserting the correct boolean expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_no_comma():\n",
    "    actual = convert_to_int(\"756\")\n",
    "    # Complete the assert statement\n",
    "    assert actual == 756, \"Expected: 756, Actual: {0}\".format(actual)\n",
    "    \n",
    "def test_with_one_comma():\n",
    "    actual = convert_to_int(\"2,081\")\n",
    "    # Complete the assert statement\n",
    "    assert actual == 2081, \"Expected: 2081, Actual: {0}\".format(actual)\n",
    "    \n",
    "def test_with_two_commas():\n",
    "    actual = convert_to_int(\"1,034,891\")\n",
    "    # Complete the assert statement\n",
    "    assert actual == 1034891, \"Expected: 1034891, Actual: {0}\".format(actual)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TDD: Requirement collection\n",
    "What should convert_to_int() do if the arguments are not normal? In particular, there are three special argument types:\n",
    "\n",
    "Arguments that are missing a comma e.g. \"178100,301\".\n",
    "Arguments that have the comma in the wrong place e.g. \"12,72,891\".\n",
    "Float valued strings e.g. \"23,816.92\".\n",
    "Also, should convert_to_int() raise an exception for specific argument values?\n",
    "\n",
    "When your boss asked you to implement the function, she didn't say anything about these cases! But since you want to write tests for special and bad arguments as a part of TDD, you go and ask your boss.\n",
    "\n",
    "She says that convert_to_int() should return None for every special argument and there are no bad arguments for this function.\n",
    "\n",
    "pytest has been imported for you.\n",
    "\n",
    "#### Instructions \n",
    "- Give a name to the test by using the standard name prefix that pytest expects followed by on_string_with_missing_comma.\n",
    "- Assign actual to the actual return value for the argument \"12,72,891\".\n",
    "- Complete the assert statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give a name to the test for an argument with missing comma\n",
    "def test_on_string_with_missing_comma():\n",
    "    actual = convert_to_int(\"178100,301\")\n",
    "    assert actual is None, \"Expected: None, Actual: {0}\".format(actual)\n",
    "    \n",
    "def test_on_string_with_incorrectly_placed_comma():\n",
    "    # Assign to the actual return value for the argument \"12,72,891\"\n",
    "    actual = convert_to_int(\"12,72,891\")\n",
    "    assert actual is None, \"Expected: None, Actual: {0}\".format(actual)\n",
    "    \n",
    "def test_on_float_valued_string():\n",
    "    actual = convert_to_int(\"23,816.92\")\n",
    "    # Complete the assert statement\n",
    "    assert actual is None, \"Expected: None, Actual: {0}\".format(actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TDD: Implement the function\n",
    "convert_to_int() returns None for the following:\n",
    "\n",
    "1. Arguments with missing thousands comma e.g. \"178100,301\". If you split the string at the comma using \"178100,301\".split(\",\"), then the resulting list [\"178100\", \"301\"] will have at least one entry with length greater than 3 e.g. \"178100\".\n",
    "\n",
    "2. Arguments with incorrectly placed comma e.g. \"12,72,891\". If you split this at the comma, then the resulting list is [\"12\", \"72\", \"891\"]. Note that the first entry is allowed to have any length between 1 and 3. But if any other entry has a length other than 3, like \"72\", then there's an incorrectly placed comma.\n",
    "\n",
    "Float valued strings e.g. \"23,816.92\". If you remove the commas and call int() on this string i.e. int(\"23816.92\"), you will get a ValueError.\n",
    "\n",
    "#### Instructions\n",
    "- Complete the if statement that checks if the i-th element of comma_separated_parts has length greater than 3.\n",
    "- Complete the if statement that checks if any entry other than the 0-th entry of comma_separated_parts has a length not equal to 3.\n",
    "- Fill in the except clause with the exception that would be raised if you try to convert a float valued integer_string_without_commas e.g. \"23,816.92\" into an int using the int() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_int1(integer_string_with_commas):\n",
    "    comma_separated_parts = integer_string_with_commas.split(\",\")\n",
    "    for i in range(len(comma_separated_parts)):\n",
    "        # Write an if statement for checking missing commas\n",
    "        if len(comma_separated_parts[i]) > 3:\n",
    "            return None\n",
    "        # Write the if statement for incorrectly placed commas\n",
    "        if i != 0 and len(comma_separated_parts[i]) != 3:\n",
    "            return None\n",
    "    integer_string_without_commas = \"\".join(comma_separated_parts)\n",
    "    try:\n",
    "        return int(integer_string_without_commas)\n",
    "    # Fill in with the correct exception for float valued argument strings\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Test Organization and Execution\n",
    "\n",
    "In any data science project, you quickly reach a point when it becomes impossible to organize and manage unit tests. In this chapter, we will learn about how to structure your test suite well, how to effortlessly execute any subset of tests and how to mark problematic tests so that your test suite always stays green. The last lesson will even enable you to add the trust-inspiring build status and code coverage badges to your own project. Complete this chapter and become a unit testing wizard!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Testing Models, Plots and Much More\n",
    "\n",
    "In this chapter, You will pick up advanced unit testing skills like setup, teardown and mocking. You will also learn how to write sanity tests for your data science models and how to test matplotlib plots. By the end of this chapter, you will be ready to test real world data science projects!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
